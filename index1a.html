<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Strict iOS-Compatible Hands-Free Voice-to-GPT Q&A</title>
  <style>
    body { font-family: sans-serif; max-width: 500px; margin: 40px auto; }
    input[type=text] { width: 70%; padding: 8px; font-size: 16px; }
    button { padding: 10px 20px; font-size: 16px; margin: 10px 0; }
    #transcript, #gptAnswer { margin-top: 20px; border: 1px solid #ccc; padding: 12px; min-height: 30px; }
    #gptAnswer { background: #f3f3f3; }
  </style>
</head>
<body>
  <h2>Strict iOS-Compatible Hands-Free Voice-to-GPT Q&A</h2>
  <div>
    <label>
      Deepgram API Key:
      <input type="text" id="dgkey" placeholder="Paste Deepgram API Key" />
    </label>
    <button id="saveDgBtn">Save</button>
  </div>
  <div>
    <label>
      OpenAI API Key:
      <input type="text" id="openaiKey" placeholder="Paste OpenAI API Key" />
    </label>
    <button id="saveOpenAIBtn">Save</button>
  </div>
  <button id="startBtn">▶️ Start Hands Free</button>
  <button id="stopBtn" style="display:none;">⏹️ Stop</button>
  <div id="transcript"></div>
  <div id="gptAnswer"></div>
  <script>
    // --- API Key Save/Load ---
    const dgkeyInput = document.getElementById("dgkey");
    const openaiKeyInput = document.getElementById("openaiKey");
    dgkeyInput.value = localStorage.getItem("deepgram_api_key") || "";
    openaiKeyInput.value = localStorage.getItem("openai_api_key") || "";
    document.getElementById("saveDgBtn").onclick = () => {
      localStorage.setItem("deepgram_api_key", dgkeyInput.value.trim());
      alert("Deepgram key saved!");
    };
    document.getElementById("saveOpenAIBtn").onclick = () => {
      localStorage.setItem("openai_api_key", openaiKeyInput.value.trim());
      alert("OpenAI key saved!");
    };

    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const transcriptDiv = document.getElementById("transcript");
    const gptAnswerDiv = document.getElementById("gptAnswer");
    let stopLoop = false;

    async function deepgramTranscribeOnceWithTimeout(timeoutMs = 2000) {
      const apiKey = dgkeyInput.value.trim();
      if (!apiKey) { alert("Enter Deepgram API key."); return null; }
      transcriptDiv.textContent = "Listening... (speak now)";
      gptAnswerDiv.textContent = "";
      let finalTranscript = "";
      let socket, mediaRecorder, stream;
      let silenceTimer = null;
      let stopped = false;

      return new Promise(async (resolve) => {
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          socket = new WebSocket('wss://api.deepgram.com/v1/listen', [ 'token', apiKey ]);

          socket.onopen = () => {
            mediaRecorder.addEventListener('dataavailable', event => {
              if (event.data.size > 0 && socket.readyState == 1) {
                socket.send(event.data);
              }
            });
            mediaRecorder.start(250);
          };

          function finish() {
            cleanup();
            resolve(finalTranscript.trim());
          }

          socket.onmessage = (message) => {
            const received = JSON.parse(message.data);
            const transcript = received.channel.alternatives[0].transcript;
            if (transcript) {
              finalTranscript += (finalTranscript ? " " : "") + transcript;
              transcriptDiv.textContent = finalTranscript;
              // Reset silence timer on new speech
              if (silenceTimer) clearTimeout(silenceTimer);
              silenceTimer = setTimeout(() => {
                stopped = true;
                if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
                if (socket && socket.readyState === 1) socket.close();
                if (stream) stream.getTracks().forEach(track => track.stop());
                finish();
              }, timeoutMs);
            }
          };

          socket.onclose = () => {
            cleanup();
            resolve(finalTranscript.trim());
          };

          socket.onerror = (error) => {
            transcriptDiv.textContent = "WebSocket error. Check API key.";
            cleanup();
            resolve(null);
          };

          function cleanup() {
            if (silenceTimer) clearTimeout(silenceTimer);
            if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
            if (stream) stream.getTracks().forEach(track => track.stop());
          }

          stopBtn.onclick = () => {
            stopped = true;
            stopLoop = true;
            if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
            if (socket && socket.readyState === 1) socket.close();
            if (stream) stream.getTracks().forEach(track => track.stop());
            cleanup();
            resolve(null);
          };

        } catch (err) {
          transcriptDiv.textContent = "Microphone access denied or error: " + err;
          resolve(null);
        }
      });
    }

    async function askGpt(userQuestion) {
      const apiKey = openaiKeyInput.value.trim();
      if (!apiKey) { alert("Enter OpenAI API key."); return ""; }
      gptAnswerDiv.textContent = "Thinking...";
      try {
        const res = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + apiKey
          },
          body: JSON.stringify({
            model: "gpt-4o",
            messages: [
              {role: "system", content: "You are a helpful assistant."},
              {role: "user", content: userQuestion}
            ]
          })
        });
        const data = await res.json();
        let answer = data.choices?.[0]?.message?.content?.trim() || "";
        if (data.error) {
          gptAnswerDiv.textContent = "API Error: " + data.error.message;
          return "";
        }
        gptAnswerDiv.textContent = answer || "No response from GPT";
        return answer;
      } catch (err) {
        gptAnswerDiv.textContent = "Request failed: " + err.message;
        return "";
      }
    }

    function speakTextWithWebSpeech(text) {
      return new Promise((resolve) => {
        const synth = window.speechSynthesis;
        if (!synth) return resolve();
        // Cancel any previous speech (important for iOS)
        synth.cancel();
        const utter = new SpeechSynthesisUtterance(text);
        utter.pitch = 1;
        utter.rate = 1;
        utter.onend = resolve;
        utter.onerror = resolve;
        synth.speak(utter);
      });
    }

    async function continuousQnALoop() {
      stopLoop = false;
      startBtn.style.display = "none";
      stopBtn.style.display = "";
      transcriptDiv.textContent = "";
      gptAnswerDiv.textContent = "";
      while (!stopLoop) {
        // 1. Listen (mic open)
        let transcript;
        try {
          transcript = await deepgramTranscribeOnceWithTimeout(2000);
        } catch (e) {
          transcriptDiv.textContent = "Mic error: " + e.message;
          break;
        }
        if (stopLoop) break;
        if (!transcript) {
          transcriptDiv.textContent = "No speech detected. Listening again...";
          continue;
        }
        if (/^(stop|exit|goodbye|cancel)$/i.test(transcript.trim())) {
          transcriptDiv.textContent = "Conversation ended.";
          break;
        }
        transcriptDiv.textContent = transcript;

        // 2. Get GPT response (mic is closed here)
        let answer = "";
        try {
          answer = await askGpt(transcript);
        } catch (e) {
          gptAnswerDiv.textContent = "GPT error: " + e.message;
        }

        // 3. Speak GPT response (mic is still closed)
        try {
          if (answer) await speakTextWithWebSpeech(answer);
        } catch (e) {
          gptAnswerDiv.textContent += "\nTTS error: " + e.message;
        }

        // 4. Now loop: mic opens again
      }
      startBtn.style.display = "";
      stopBtn.style.display = "none";
    }

    startBtn.onclick = () => {
      stopLoop = false;
      continuousQnALoop();
    };
    stopBtn.onclick = () => { stopLoop = true; };

  </script>
</body>
</html>
